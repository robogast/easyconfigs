name = 'PyTorch'
version = '1.12.0'
versionsuffix = '-CUDA-%(cudaver)s'

homepage = 'https://pytorch.org/'
description = """Tensors and Dynamic neural networks in Python with strong GPU acceleration.
PyTorch is a deep learning framework that puts Python first."""

toolchain = {'name': 'intel', 'version': '2022a'}

sources = [
    {'filename': SOURCE_TAR_GZ, 'git_config': {'url': 'https://github.com/%(namelower)s', 'repo_name': '%(namelower)s', 'tag': 'v%(version)s', 'recursive': True}},
]
patches = [
    '%(name)s-1.7.0_avoid-nan-in-test-torch.patch',
    '%(name)s-1.7.0_disable-dev-shm-test.patch',
    '%(name)s-1.8.1_dont-use-gpu-ccc-in-test.patch',
    '%(name)s-1.9.0_limit-world-size-for-zero-redundancy-opt-test.patch',
    '%(name)s-1.10.0_fix-test-dataloader-fixed-affinity.patch',
    '%(name)s-1.10.0_skip_cmake_rpath.patch',
    '%(name)s-1.11.0_increase-distributed-test-timeout.patch',
    '%(name)s-1.11.0_skip_failing_ops_tests.patch',
    '%(name)s-1.11.0_fix_skip_jit_cuda_fuser.patch',
    '%(name)s-1.11.0_fix_sharded_imports.patch',
    '%(name)s-1.11.0_increase_test_tolerances_TF32.patch',
    '%(name)s-1.11.0_increase_c10d_gloo_timeout.patch',
    '%(name)s-1.11.0_disable_failing_jit_cuda_fuser_tests.patch',
]

builddependencies = [
    ('CMake', '3.23.1'),
    ('hypothesis', '6.46.7'),
]
dependencies = [
    ('CUDA', '11.7.0', '', True),
    ('Ninja', '1.10.2'),  # Required for JIT compilation of C++ extensions
    ('Python', '3.10.4'),
    ('protobuf', '3.19.4'),
    ('protobuf-python', '3.19.4'),
    ('pybind11', '2.9.2'),
    ('SciPy-bundle', '2022.05'),
    ('typing-extensions', '4.3.0'),
    ('PyYAML', '6.0'),
    ('MPFR', '4.1.0'),
    ('GMP', '6.2.1'),
    ('numactl', '2.0.14'),
    ('FFmpeg', '5.0.1'),
    ('Pillow', '9.1.1'),
    ('cuDNN', '8.4.1.50', '-CUDA-%(cudaver)s', True),
    ('magma', '2.6.2', '-CUDA-%(cudaver)s'),
    ('NCCL', '2.12.12', '-CUDA-%(cudaver)s'),
    ('expecttest', '0.1.3'),
]

osdependencies = [('libibverbs-dev', 'libibverbs-devel', 'rdma-core-devel')]

# default CUDA compute capabilities to use (override via --cuda-compute-capabilities)
cuda_compute_capabilities = [
    '3.5',
    '3.7',
    '5.2',
    '6.0',
    '6.1',
    '7.0',
    '7.2',
    '7.5',
    '%(cuda_cc_space_sep)s',
    '8.6',
]
runtest = "cd test && PYTHONUNBUFFERED=1 %(python)s run_test.py --continue-through-error  --verbose %(excluded_tests)s"
tests = ['%(name)s-check-cpp-extension.py']
custom_opts = ['USE_CUPTI_SO=1']
excluded_tests = {
    '': ['distributed/elastic/utils/distributed_test', 'distributed/elastic/multiprocessing/api_test', 'distributed/test_distributed_spawn', 'test_optim', 'test_model_dump', 'distributed/fsdp/test_fsdp_memory', 'distributed/fsdp/test_fsdp_overlap'],
}
# several tests are known to be flaky, and fail in some contexts (like having multiple GPUs available),
# so we allow up to 10 (out of ~90k) tests to fail before treating the installation to be faulty
max_failed_tests = 10

sanity_check_commands = [
    "readelf -d $EBROOTPYTORCH/lib/python%(pyshortver)s/site-packages/torch/lib/libcaffe2_nvrtc.so | egrep 'RPATH|RUNPATH' | grep -v stubs",
]

moduleclass = 'devel'
